#!/usr/bin/env python3
"""
Ollama ì—°ë™ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import requests
import json
from typing import Dict, Any

def test_ollama_connection():
    """Ollama ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        print("ğŸ” Ollama ì„œë¹„ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸...")
        
        # Health check
        response = requests.get("http://localhost:11434/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… Ollama ì„œë¹„ìŠ¤ ì •ìƒ - {len(models)}ê°œ ëª¨ë¸ ì„¤ì¹˜ë¨")
            for model in models:
                name = model.get('name', 'Unknown')
                size = model.get('size', 0)
                print(f"   ğŸ“¦ {name} ({size//1000000}MB)")
            return True
        else:
            print(f"âŒ Ollama ì„œë¹„ìŠ¤ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            print(f"   ì‘ë‹µ ë‚´ìš©: {response.text}")
            return False
            
    except requests.exceptions.ConnectionError:
        print("âŒ Ollama ì„œë¹„ìŠ¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print("   í•´ê²°ì±…:")
        print("   1. systemctl start ollama")
        print("   2. ollama serve")
        print("   3. í¬íŠ¸ 11434 í™•ì¸: ss -tlnp | grep 11434")
        return False
    except requests.exceptions.Timeout:
        print("âŒ Ollama ì„œë¹„ìŠ¤ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        print("   ì„œë¹„ìŠ¤ê°€ ì‹œì‘ ì¤‘ì´ê±°ë‚˜ ê³¼ë¶€í•˜ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        return False
    except Exception as e:
        print(f"âŒ Ollama ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_ollama_generation():
    """Ollama AI ìƒì„± í…ŒìŠ¤íŠ¸"""
    try:
        print("\nğŸ¤– Ollama AI ìƒì„± í…ŒìŠ¤íŠ¸...")
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.1:8b",
                "prompt": "ì•ˆë…•í•˜ì„¸ìš”. ê°„ë‹¨í•œ íˆ¬ì ì¡°ì–¸ì„ í•œ ì¤„ë¡œ í•´ì£¼ì„¸ìš”.",
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "max_tokens": 100
                }
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_response = result.get("response", "")
            print(f"âœ… AI ì‘ë‹µ ì„±ê³µ: {ai_response[:100]}...")
            return True
        else:
            print(f"âŒ AI ìƒì„± ì‹¤íŒ¨: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ AI ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_python_ollama_package():
    """Python ollama íŒ¨í‚¤ì§€ í…ŒìŠ¤íŠ¸"""
    try:
        print("\nğŸ“¦ Python ollama íŒ¨í‚¤ì§€ í…ŒìŠ¤íŠ¸...")
        import ollama
        print("âœ… ollama íŒ¨í‚¤ì§€ import ì„±ê³µ")
        return True
    except ImportError:
        print("âŒ ollama íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ í•„ìš”:")
        print("   pip install ollama")
        return False
    except Exception as e:
        print(f"âŒ ollama íŒ¨í‚¤ì§€ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ§ª Ollama ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tests = [
        test_python_ollama_package(),
        test_ollama_connection(), 
        test_ollama_generation()
    ]
    
    # ê²°ê³¼ ìš”ì•½
    passed = sum(tests)
    total = len(tests)
    
    print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! Ollamaê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ì˜ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")