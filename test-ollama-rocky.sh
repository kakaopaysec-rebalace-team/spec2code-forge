#!/bin/bash

echo "ðŸ” Rocky Linux - Ollama í†µì‹  ìƒíƒœ ì¢…í•© ì ê²€"
echo "=================================================="

# ìƒ‰ìƒ ì„¤ì •
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ì ê²€ ê²°ê³¼ ì €ìž¥
RESULTS=()
ERROR_COUNT=0

# ë¡œê·¸ í•¨ìˆ˜
log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
    RESULTS+=("âœ… $1")
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
    RESULTS+=("âŒ $1")
    ((ERROR_COUNT++))
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
    RESULTS+=("âš ï¸  $1")
}

log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

echo ""
echo "1. ðŸ“‹ ì‹œìŠ¤í…œ ê¸°ë³¸ ì •ë³´"
echo "===================="
log_info "OS ì •ë³´: $(cat /etc/os-release | grep PRETTY_NAME | cut -d'"' -f2)"
log_info "ì»¤ë„ ë²„ì „: $(uname -r)"
log_info "í˜„ìž¬ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"
log_info "ì„œë²„ IP: $(hostname -I | awk '{print $1}')"

echo ""
echo "2. ðŸ”Œ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì ê²€"
echo "======================"

# í¬íŠ¸ 11434 ìƒíƒœ í™•ì¸
if ss -tlnp | grep -q ":11434"; then
    PORT_INFO=$(ss -tlnp | grep ":11434")
    log_success "í¬íŠ¸ 11434 í™œì„±í™”ë¨"
    log_info "í¬íŠ¸ ìƒì„¸: $PORT_INFO"
else
    log_error "í¬íŠ¸ 11434ê°€ ë¹„í™œì„±í™” ìƒíƒœ"
    log_info "í•´ê²°ë°©ë²•: systemctl start ollama ë˜ëŠ” ollama serve"
fi

# localhost ì—°ê²° í…ŒìŠ¤íŠ¸
if curl -s --connect-timeout 3 http://localhost:11434 >/dev/null 2>&1; then
    log_success "localhost:11434 ì—°ê²° ê°€ëŠ¥"
else
    log_error "localhost:11434 ì—°ê²° ì‹¤íŒ¨"
fi

echo ""
echo "3. ðŸ¤– Ollama ì„œë¹„ìŠ¤ ìƒíƒœ"
echo "======================"

# systemctl ìƒíƒœ í™•ì¸
if systemctl is-active --quiet ollama 2>/dev/null; then
    log_success "Ollama systemd ì„œë¹„ìŠ¤ í™œì„±í™”ë¨"
    OLLAMA_STATUS=$(systemctl status ollama --no-pager -l | head -10)
    log_info "ì„œë¹„ìŠ¤ ìƒíƒœ:"
    echo "$OLLAMA_STATUS" | while read line; do
        echo "    $line"
    done
else
    log_warning "Ollama systemd ì„œë¹„ìŠ¤ê°€ ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ìˆ˜ë™ ì‹¤í–‰ ì¤‘"
fi

# í”„ë¡œì„¸ìŠ¤ í™•ì¸
if pgrep -f "ollama" >/dev/null; then
    OLLAMA_PROC=$(ps aux | grep ollama | grep -v grep)
    log_success "Ollama í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘"
    log_info "í”„ë¡œì„¸ìŠ¤ ì •ë³´:"
    echo "$OLLAMA_PROC" | while read line; do
        echo "    $line"
    done
else
    log_error "Ollama í”„ë¡œì„¸ìŠ¤ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ"
fi

echo ""
echo "4. ðŸ“¦ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸"
echo "===================="

# APIë¥¼ í†µí•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
MODEL_RESPONSE=$(curl -s --connect-timeout 10 http://localhost:11434/api/tags 2>/dev/null)
if [ $? -eq 0 ] && [ -n "$MODEL_RESPONSE" ]; then
    MODEL_COUNT=$(echo "$MODEL_RESPONSE" | grep -o '"name"' | wc -l)
    if [ "$MODEL_COUNT" -gt 0 ]; then
        log_success "ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì„±ê³µ - $MODEL_COUNTê°œ ëª¨ë¸ ì„¤ì¹˜ë¨"
        
        # ëª¨ë¸ ìƒì„¸ ì •ë³´ íŒŒì‹±
        echo "$MODEL_RESPONSE" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    for model in data.get('models', []):
        name = model.get('name', 'Unknown')
        size = model.get('size', 0)
        size_mb = size // 1000000
        modified = model.get('modified_at', '')[:19].replace('T', ' ')
        print(f'    ðŸ“¦ {name} ({size_mb}MB) - ìˆ˜ì •ì¼: {modified}')
except:
    pass
" 2>/dev/null || log_info "ëª¨ë¸ ìƒì„¸ ì •ë³´ íŒŒì‹± ì‹¤íŒ¨"
    else
        log_warning "ì„¤ì¹˜ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤"
    fi
else
    log_error "ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ - Ollama API ì‘ë‹µ ì—†ìŒ"
fi

echo ""
echo "5. ðŸ§ª ì‹¤ì œ AI ìƒì„± í…ŒìŠ¤íŠ¸"
echo "======================="

# ì‹¤ì œ ìƒì„± í…ŒìŠ¤íŠ¸
log_info "AI ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œìž‘ (ìµœëŒ€ 60ì´ˆ ëŒ€ê¸°)..."

AI_TEST_START=$(date +%s)
AI_RESPONSE=$(timeout 60 curl -s -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d '{
        "model": "llama3.1:8b",
        "prompt": "ì•ˆë…•í•˜ì„¸ìš”. í•œêµ­ íˆ¬ìžìžë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ì¡°ì–¸ í•œ ì¤„ ë¶€íƒí•´ìš”.",
        "stream": false,
        "options": {"temperature": 0.1, "max_tokens": 50}
    }' 2>/dev/null)

AI_TEST_END=$(date +%s)
AI_TEST_DURATION=$((AI_TEST_END - AI_TEST_START))

if [ $? -eq 0 ] && [ -n "$AI_RESPONSE" ]; then
    # ì‘ë‹µì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    AI_TEXT=$(echo "$AI_RESPONSE" | python3 -c "
import sys, json
try:
    data = json.load(sys.stdin)
    response = data.get('response', '').strip()
    if response:
        print(response[:100] + ('...' if len(response) > 100 else ''))
except:
    pass
" 2>/dev/null)
    
    if [ -n "$AI_TEXT" ]; then
        log_success "AI ìƒì„± í…ŒìŠ¤íŠ¸ ì„±ê³µ (ì†Œìš”ì‹œê°„: ${AI_TEST_DURATION}ì´ˆ)"
        log_info "ì‘ë‹µ ë‚´ìš©: $AI_TEXT"
    else
        log_error "AI ì‘ë‹µì€ ë°›ì•˜ìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ìžˆìŒ"
        log_info "ì›ë³¸ ì‘ë‹µ: ${AI_RESPONSE:0:200}..."
    fi
else
    log_error "AI ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: ${AI_TEST_DURATION}ì´ˆ)"
    if [ "$AI_TEST_DURATION" -ge 60 ]; then
        log_warning "íƒ€ìž„ì•„ì›ƒ ë°œìƒ - Ollamaê°€ ê³¼ë¶€í•˜ ìƒíƒœì´ê±°ë‚˜ ì‘ë‹µì´ ëŠë¦¼"
    fi
fi

echo ""
echo "6. ðŸ”§ Python í™˜ê²½ ì ê²€"
echo "===================="

# Python íŒ¨í‚¤ì§€ í™•ì¸
if python3 -c "import requests" 2>/dev/null; then
    log_success "requests íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨"
else
    log_error "requests íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜"
    log_info "ì„¤ì¹˜ë°©ë²•: pip install requests"
fi

if python3 -c "import httpx" 2>/dev/null; then
    log_success "httpx íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨"
else
    log_warning "httpx íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ (ë¹„ë™ê¸° í†µì‹ ìš©)"
    log_info "ì„¤ì¹˜ë°©ë²•: pip install httpx"
fi

if python3 -c "import ollama" 2>/dev/null; then
    log_success "ollama íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨"
else
    log_warning "ollama íŒ¨í‚¤ì§€ ë¯¸ì„¤ì¹˜ (ì„ íƒì‚¬í•­)"
    log_info "ì„¤ì¹˜ë°©ë²•: pip install ollama"
fi

echo ""
echo "7. ðŸ’¾ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìƒíƒœ"
echo "======================="

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
MEMORY_INFO=$(free -h | grep "Mem:")
log_info "ë©”ëª¨ë¦¬ ìƒíƒœ: $MEMORY_INFO"

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ (Ollama ëª¨ë¸ ì €ìž¥ ìœ„ì¹˜)
DISK_INFO=$(df -h /home 2>/dev/null || df -h /)
log_info "ë””ìŠ¤í¬ ìƒíƒœ:"
echo "$DISK_INFO" | while read line; do
    echo "    $line"
done

# CPU ë¡œë“œ
LOAD_AVG=$(uptime | awk -F'load average:' '{print $2}')
log_info "CPU ë¡œë“œ í‰ê· :$LOAD_AVG"

echo ""
echo "8. ðŸ” ë°©í™”ë²½ ë° ë³´ì•ˆ ì ê²€"
echo "======================="

# firewalld ìƒíƒœ
if systemctl is-active --quiet firewalld; then
    log_info "firewalld í™œì„±í™”ë¨"
    if firewall-cmd --list-ports 2>/dev/null | grep -q "11434"; then
        log_success "í¬íŠ¸ 11434ê°€ ë°©í™”ë²½ì—ì„œ í—ˆìš©ë¨"
    else
        log_warning "í¬íŠ¸ 11434ê°€ ë°©í™”ë²½ì—ì„œ ì°¨ë‹¨ë  ìˆ˜ ìžˆìŒ"
        log_info "í—ˆìš©ë°©ë²•: firewall-cmd --add-port=11434/tcp --permanent && firewall-cmd --reload"
    fi
else
    log_info "firewalld ë¹„í™œì„±í™”ë¨"
fi

# SELinux ìƒíƒœ
if command -v getenforce >/dev/null 2>&1; then
    SELINUX_STATUS=$(getenforce 2>/dev/null)
    log_info "SELinux ìƒíƒœ: $SELINUX_STATUS"
    if [ "$SELINUX_STATUS" = "Enforcing" ]; then
        log_warning "SELinuxê°€ ê°•ì œ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ - í†µì‹  ë¬¸ì œ ê°€ëŠ¥ì„±"
    fi
fi

echo ""
echo "ðŸ“Š ì ê²€ ê²°ê³¼ ìš”ì•½"
echo "================"

if [ $ERROR_COUNT -eq 0 ]; then
    echo -e "${GREEN}ðŸŽ‰ ëª¨ë“  ì ê²€ í•­ëª©ì´ ì •ìƒìž…ë‹ˆë‹¤!${NC}"
    echo "Ollamaê°€ ì •ìƒì ìœ¼ë¡œ ìž‘ë™í•˜ê³  ìžˆìŠµë‹ˆë‹¤."
else
    echo -e "${RED}âš ï¸  $ERROR_COUNT ê°œì˜ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.${NC}"
    echo "ì•„ëž˜ í•´ê²°ë°©ë²•ì„ ì°¸ê³ í•˜ì„¸ìš”:"
    echo ""
    echo "ì£¼ìš” í•´ê²°ë°©ë²•:"
    echo "1. Ollama ì„œë¹„ìŠ¤ ì‹œìž‘: systemctl start ollama"
    echo "2. Ollama ìˆ˜ë™ ì‹¤í–‰: ollama serve"
    echo "3. ëª¨ë¸ ì„¤ì¹˜: ollama pull llama3.1:8b"
    echo "4. Python íŒ¨í‚¤ì§€: pip install requests httpx"
    echo "5. ë°©í™”ë²½ í—ˆìš©: firewall-cmd --add-port=11434/tcp --permanent"
fi

echo ""
echo "ìƒì„¸ ì ê²€ ê²°ê³¼:"
printf '%s\n' "${RESULTS[@]}"

echo ""
echo "ì ê²€ ì™„ë£Œ ì‹œê°„: $(date '+%Y-%m-%d %H:%M:%S')"
echo "ë¡œê·¸ ì €ìž¥ ìœ„ì¹˜: ì´ ìŠ¤í¬ë¦½íŠ¸ ì¶œë ¥ì„ íŒŒì¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸í•˜ì—¬ ì €ìž¥ ê°€ëŠ¥"
echo "ì‚¬ìš©ë²•: ./test-ollama-rocky.sh > ollama-check-$(date +%Y%m%d-%H%M%S).log 2>&1"